{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor, optim, cuda\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import Tensor, optim, cuda\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "import os\n",
    "from tensorboardX import SummaryWriter\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from data.datasets import DeClareDataset\n",
    "from model.deClare import DeClareModel\n",
    "from metrics.evaluation import DeClareEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOPES_LOC = \"./Datasets/Snopes/snopes.tsv\"\n",
    "#consists of rumors analyzed on the Snopes website along with their credibility labels (true or false), \n",
    "#sets of reporting articles, and their respective web sources\n",
    "\n",
    "POLITIFACT_LOC = \"./Datasets/PolitiFact/politifact.tsv\"\n",
    "\n",
    "glove_data_file = \"./Glove/glove.6B.100d.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read news data from ./Datasets/Snopes/snopes.tsv\n",
      "Number of articles = 29242\n",
      "Number of claims = 4341\n",
      "Using pre-built vocabulary\n"
     ]
    }
   ],
   "source": [
    "snopes = DeClareDataset(SNOPES_LOC, glove_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Credibility</th>\n",
       "      <th>Claim_Source</th>\n",
       "      <th>Claim</th>\n",
       "      <th>Article</th>\n",
       "      <th>Article_Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>there are several holidays throughout that tim...</td>\n",
       "      <td>www.godlikeproductions.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>defenses against same photographs show images ...</td>\n",
       "      <td>www.sjpba.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>the best that life could think out we extended...</td>\n",
       "      <td>www.englisher.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>this entry november 19 2006 published 9 years ...</td>\n",
       "      <td>rss2.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>politics_christmas_bestbuy</td>\n",
       "      <td>best buy chain eschewing use word christmas 20...</td>\n",
       "      <td>place he will not do either said snape the ord...</td>\n",
       "      <td>www.englisher.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Credibility                Claim_Source  \\\n",
       "0        true  politics_christmas_bestbuy   \n",
       "1        true  politics_christmas_bestbuy   \n",
       "2        true  politics_christmas_bestbuy   \n",
       "3        true  politics_christmas_bestbuy   \n",
       "4        true  politics_christmas_bestbuy   \n",
       "\n",
       "                                               Claim  \\\n",
       "0  best buy chain eschewing use word christmas 20...   \n",
       "1  best buy chain eschewing use word christmas 20...   \n",
       "2  best buy chain eschewing use word christmas 20...   \n",
       "3  best buy chain eschewing use word christmas 20...   \n",
       "4  best buy chain eschewing use word christmas 20...   \n",
       "\n",
       "                                             Article  \\\n",
       "0  there are several holidays throughout that tim...   \n",
       "1  defenses against same photographs show images ...   \n",
       "2  the best that life could think out we extended...   \n",
       "3  this entry november 19 2006 published 9 years ...   \n",
       "4  place he will not do either said snape the ord...   \n",
       "\n",
       "               Article_Source  \n",
       "0  www.godlikeproductions.com  \n",
       "1               www.sjpba.net  \n",
       "2           www.englisher.net  \n",
       "3                    rss2.com  \n",
       "4           www.englisher.net  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snopes.news_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_lstm_units = 64\n",
    "random_seed = 42\n",
    "\n",
    "val_split = 0.1\n",
    "test_split = 0.1\n",
    "shuffle_dataset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(snopes)\n",
    "indices = list(range(dataset_size))\n",
    "\n",
    "val_split = int(np.floor(val_split * dataset_size))\n",
    "test_split = val_split + int(np.floor(test_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices, test_indices = indices[test_split:], indices[:val_split], indices[val_split:test_split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(snopes, batch_size, sampler=train_sampler)\n",
    "val_dataloader = DataLoader(snopes, len(val_indices), sampler=val_sampler)\n",
    "test_dataloader = DataLoader(snopes, len(test_indices), sampler=test_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeClareModel(\n",
       "  (word_embeddings): Embedding(56755, 100)\n",
       "  (claim_source_embeddings): Embedding(4342, 4)\n",
       "  (article_source_embeddings): Embedding(12237, 8)\n",
       "  (attention_dense): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (attention_dropout): Dropout(p=0.5)\n",
       "  (dense_1): Linear(in_features=140, out_features=64, bias=True)\n",
       "  (dense_1_dropout): Dropout(p=0.5)\n",
       "  (dense_2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (dense_2_dropout): Dropout(p=0.5)\n",
       "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (biLSTM): LSTM(100, 64, batch_first=True, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "declare = DeClareModel(snopes.initial_embeddings, snopes.claim_source_vocab_size, \n",
    "                       snopes.article_source_vocab_size, nb_lstm_units, device)\n",
    "\n",
    "declare.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(declare.parameters(), lr=0.005)\n",
    "BCEloss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e506adaad47f401495a770d96297b66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/Software/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu/Software/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([34])) that is different to the input size (torch.Size([34, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ff57eec1cb4dae9b6449de790a6e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca0c7f62d914f70977a1bd8bf1e56e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf5c62d903344c3af83858370585450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "962084e05dd1443fb2f5938d457c4cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbedfb7f183a4f8a880bde0266a81103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f3b69c18754b8eb887009ce3d5c4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9cfdf6ce244a9597364fa435f439ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61789647e00a4689870701db62b7a4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3767a0293d64e48b0414f690ab83f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33200577d9bd452e8c7ab55e859c1c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff32807926234e779f46f489b9be030f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939405925147497cad5aa12e49216361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe8e733e44741e193cd110df105c110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3948742fc24dd7bdad407039c0aee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c858741821f46568e9690fe84d7efc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0599507fd7bd4e0f93c788d5b290b175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5e2e055f6848bd9b90a49dc5b09a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5962bfd09b714dab91288db100b76d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=366), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = {}\n",
    "num_epochs = 20\n",
    "reg_lambda = 0.0002\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses[epoch] = []\n",
    "    for data_sample in tqdm(train_dataloader):\n",
    "        \n",
    "        declare.zero_grad()\n",
    "        idx = np.argsort(-data_sample[3])\n",
    "\n",
    "        for i in range(len(data_sample)):\n",
    "            data_sample[i] = data_sample[i][idx].to(device)\n",
    "\n",
    "        out = declare(data_sample[0], data_sample[1], data_sample[2], data_sample[3], data_sample[4], data_sample[5])\n",
    "        loss = BCEloss(out, data_sample[6].float())\n",
    "\n",
    "        l2_reg = None\n",
    "        for param in declare.named_parameters():\n",
    "            if 'dense' in param[0] and 'weight' in param[0]:\n",
    "                if l2_reg is None:\n",
    "                    l2_reg = param[1].norm(2)\n",
    "                else:\n",
    "                    l2_reg = l2_reg + param[1].norm(2)\n",
    "\n",
    "        total_loss = loss + reg_lambda*l2_reg\n",
    "\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        writer.add_scalar('total loss', total_loss, epoch)\n",
    "        writer.add_scalar('regularization loss', l2_reg, epoch)\n",
    "        writer.add_scalar('loss', loss, epoch)\n",
    "        writer.add_scalar('pad embedding', declare.word_embeddings(torch.tensor([0]).to(device)).data.mean())\n",
    "        \n",
    "        losses[epoch].append(total_loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(declare.state_dict(), 'demo_model')\n",
    "# declare.load_state_dict(torch.load('demo_model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snopes_eval = DeClareEvaluation(declare, test_dataloader, device)\n",
    "labels, preds = snopes_eval.claim_wise_accuracies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_claim_indices = np.where(labels==1)\n",
    "false_claim_indices = np.where(labels==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(labels[true_claim_indices], preds[true_claim_indices]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(labels[false_claim_indices], preds[false_claim_indices]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potifact_df = pd.read_csv(POLITIFACT_LOC, sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "potifact_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snopes_df = pd.read_csv(SNOPES_LOC, sep='\\t', header=None)\n",
    "snopes_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
